{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liste des modèles à tester (et des hyper-paramètres correspondants)\n",
    "* régression linéaire régularisée (*elastic net*)\n",
    "    * équilibre entre la régularisation l1 et la régularisation l2\n",
    "    * intensité de la régularisation\n",
    "\n",
    "\n",
    "* machine à vecteur de support à noyau pour la régression (k-SVR)\n",
    "    * C : pénalité pour la mauvaise classification (absent pour la régression ?)\n",
    "    * kernel : nature du noyau (linéaire, gaussien, etc.)\n",
    "    * gamma : paramètre pour le noyau gaussien\n",
    "\n",
    "\n",
    "* forêt aléatoire pour la régression (*random forest regressor*)\n",
    "    * max_features : nombre de variables à prendre en compte à chaque noeud\n",
    "    * n_estimators : nombre d'arbres de décisions à entraîner\n",
    "    \n",
    "\n",
    "* AdaBoost\n",
    "    * n_estimators : nombre d'arbres de décisions à entraîner\n",
    "    * learning_rate : contrôle la vitesse d'apprentissage via la contribution de chaque modèle à la pondération\n",
    "    * loss : définition de la fonction de perte (linear, square, exponential)\n",
    "    \n",
    "    \n",
    "* k-plus proches voisins pour la régression (k-NN regressor)\n",
    "    * k : nombre de voisins considérés\n",
    "    \n",
    "    \n",
    "* réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données nettoyées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BuildingType</th>\n",
       "      <th>PrimaryPropertyType</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>PropertyGFAParking</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>LargestPropertyUseType</th>\n",
       "      <th>LargestPropertyUseTypeGFA</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>SiteEnergyUse(kBtu)</th>\n",
       "      <th>TotalGHGEmissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multifamily LR (1-4)</td>\n",
       "      <td>Low-Rise Multifamily</td>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>48383.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48383.0</td>\n",
       "      <td>Multifamily Housing</td>\n",
       "      <td>38172.000000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2953338.0</td>\n",
       "      <td>112.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multifamily LR (1-4)</td>\n",
       "      <td>Low-Rise Multifamily</td>\n",
       "      <td>DELRIDGE</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52134.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52134.0</td>\n",
       "      <td>Multifamily Housing</td>\n",
       "      <td>52134.000000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1212551.0</td>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NonResidential</td>\n",
       "      <td>Retail Store</td>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111077.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111077.0</td>\n",
       "      <td>Retail Store</td>\n",
       "      <td>101528.658703</td>\n",
       "      <td>91.0</td>\n",
       "      <td>9898724.0</td>\n",
       "      <td>69.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NonResidential</td>\n",
       "      <td>Small- and Mid-Sized Office</td>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>98370.0</td>\n",
       "      <td>25920.0</td>\n",
       "      <td>72450.0</td>\n",
       "      <td>Office</td>\n",
       "      <td>98370.000000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6525887.0</td>\n",
       "      <td>47.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NonResidential</td>\n",
       "      <td>Large Office</td>\n",
       "      <td>LAKE UNION</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>193788.0</td>\n",
       "      <td>37854.0</td>\n",
       "      <td>155934.0</td>\n",
       "      <td>Office</td>\n",
       "      <td>138672.000000</td>\n",
       "      <td>59.0</td>\n",
       "      <td>16760217.0</td>\n",
       "      <td>116.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BuildingType          PrimaryPropertyType Neighborhood  YearBuilt  \\\n",
       "0  Multifamily LR (1-4)         Low-Rise Multifamily     DOWNTOWN     1900.0   \n",
       "1  Multifamily LR (1-4)         Low-Rise Multifamily     DELRIDGE     2007.0   \n",
       "2        NonResidential                 Retail Store     DOWNTOWN     1989.0   \n",
       "3        NonResidential  Small- and Mid-Sized Office     DOWNTOWN     1906.0   \n",
       "4        NonResidential                 Large Office   LAKE UNION     1947.0   \n",
       "\n",
       "   NumberofBuildings  NumberofFloors  PropertyGFATotal  PropertyGFAParking  \\\n",
       "0                1.0             4.0           48383.0                 0.0   \n",
       "1                1.0             4.0           52134.0                 0.0   \n",
       "2                1.0             4.0          111077.0                 0.0   \n",
       "3                1.0             6.0           98370.0             25920.0   \n",
       "4                1.0             4.0          193788.0             37854.0   \n",
       "\n",
       "   PropertyGFABuilding(s) LargestPropertyUseType  LargestPropertyUseTypeGFA  \\\n",
       "0                 48383.0    Multifamily Housing               38172.000000   \n",
       "1                 52134.0    Multifamily Housing               52134.000000   \n",
       "2                111077.0           Retail Store              101528.658703   \n",
       "3                 72450.0                 Office               98370.000000   \n",
       "4                155934.0                 Office              138672.000000   \n",
       "\n",
       "   ENERGYSTARScore  SiteEnergyUse(kBtu)  TotalGHGEmissions  \n",
       "0             75.0            2953338.0             112.06  \n",
       "1             85.0            1212551.0               8.45  \n",
       "2             91.0            9898724.0              69.01  \n",
       "3             45.0            6525887.0              47.24  \n",
       "4             59.0           16760217.0             116.84  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load binary file with cleaned data\n",
    "data = pd.read_feather(\"p4_data4.ft\")\n",
    "\n",
    "# Display head of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Deleting index (\"level_0\")\n",
    "data = data.drop(columns=[\"level_0\"])\n",
    "\n",
    "# Display head of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation\n",
    "Nous cherchons à élaborer un modèle de prédiction des émissions de CO2 et de la consommation totale d'énergie à partir d'un jeu de données.\n",
    "\n",
    "Il s'agit donc d'un problème « *machine learning* » de régression (donc un problème d'apprentissage supervisé)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des variables explicatives (features) et des étiquettes (targets)\n",
    "Il y a deux variables à estimer :\n",
    "* 'TotalGHGEmissions': *The total amount of greenhouse gas emissions, including carbon dioxide, methane, and nitrous oxide gases released into the atmosphere as a result of energy consumption at the property, measured in metric tons of carbon dioxide equivalent.*\n",
    "* 'SiteEnergyUse(kBtu)': *The annual amount of energy consumed by the property from all sources of energy.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation du jeu de données étiquettées et du jeu de données non-étiquettées\n",
    "Nous avons vu précédemment que certaines données (en fait, une seule) n'ont pas de valeurs renseignées pour la valeur cible.\n",
    "Nous allons mettre à part ces lignes pour un traitement avec notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_target(dataframe, target):\n",
    "    \"\"\"This function takes a dataframe and target feature, and returns\n",
    "    a view of the dataframe containing the rows where the target value is missing.\n",
    "    It also remove these rows from the original dataframe.\"\"\"\n",
    "    \n",
    "    # Mask for rows where the target value is missing\n",
    "    mask = dataframe[target].isnull()\n",
    "    \n",
    "    # Applying the mask to the dataframe and saving it as a copy\n",
    "    result = dataframe[mask].copy()\n",
    "    \n",
    "    # Deleting the rows with missing target from the dataframe\n",
    "    dataframe.dropna(subset=[target], inplace=True)\n",
    "    \n",
    "    # Returning a dataframe with rows where target is missing\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BuildingType</th>\n",
       "      <th>PrimaryPropertyType</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>PropertyGFAParking</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>LargestPropertyUseType</th>\n",
       "      <th>LargestPropertyUseTypeGFA</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>SiteEnergyUse(kBtu)</th>\n",
       "      <th>TotalGHGEmissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SPS-District K-12</td>\n",
       "      <td>K-12 School</td>\n",
       "      <td>NORTHWEST</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110830.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110830.0</td>\n",
       "      <td>K-12 School</td>\n",
       "      <td>110830.000000</td>\n",
       "      <td>67.676080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Multifamily LR (1-4)</td>\n",
       "      <td>Low-Rise Multifamily</td>\n",
       "      <td>MAGNOLIA / QUEEN ANNE</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>0.705243</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23636.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23636.0</td>\n",
       "      <td>Low-Rise Multifamily</td>\n",
       "      <td>18758.287287</td>\n",
       "      <td>67.396583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Multifamily LR (1-4)</td>\n",
       "      <td>Low-Rise Multifamily</td>\n",
       "      <td>NORTHEAST</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33166.0</td>\n",
       "      <td>Low-Rise Multifamily</td>\n",
       "      <td>27778.915621</td>\n",
       "      <td>67.433917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Multifamily LR (1-4)</td>\n",
       "      <td>Low-Rise Multifamily</td>\n",
       "      <td>EAST</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36685.0</td>\n",
       "      <td>8254.0</td>\n",
       "      <td>28431.0</td>\n",
       "      <td>Low-Rise Multifamily</td>\n",
       "      <td>25186.251336</td>\n",
       "      <td>67.813506</td>\n",
       "      <td>820220.125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             BuildingType   PrimaryPropertyType           Neighborhood  \\\n",
       "36      SPS-District K-12           K-12 School              NORTHWEST   \n",
       "65   Multifamily LR (1-4)  Low-Rise Multifamily  MAGNOLIA / QUEEN ANNE   \n",
       "900  Multifamily LR (1-4)  Low-Rise Multifamily              NORTHEAST   \n",
       "120  Multifamily LR (1-4)  Low-Rise Multifamily                   EAST   \n",
       "\n",
       "     YearBuilt  NumberofBuildings  NumberofFloors  PropertyGFATotal  \\\n",
       "36      1953.0           1.000000             1.0          110830.0   \n",
       "65      1957.0           0.705243             4.0           23636.0   \n",
       "900     1977.0           1.000000             3.0           33166.0   \n",
       "120     2015.0           1.000000             4.0           36685.0   \n",
       "\n",
       "     PropertyGFAParking  PropertyGFABuilding(s) LargestPropertyUseType  \\\n",
       "36                  0.0                110830.0            K-12 School   \n",
       "65                  0.0                 23636.0   Low-Rise Multifamily   \n",
       "900                 0.0                 33166.0   Low-Rise Multifamily   \n",
       "120              8254.0                 28431.0   Low-Rise Multifamily   \n",
       "\n",
       "     LargestPropertyUseTypeGFA  ENERGYSTARScore  SiteEnergyUse(kBtu)  \\\n",
       "36               110830.000000        67.676080                  NaN   \n",
       "65                18758.287287        67.396583                  NaN   \n",
       "900               27778.915621        67.433917                  NaN   \n",
       "120               25186.251336        67.813506           820220.125   \n",
       "\n",
       "     TotalGHGEmissions  \n",
       "36                 NaN  \n",
       "65                 NaN  \n",
       "900                NaN  \n",
       "120                NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cols = ['SiteEnergyUse(kBtu)','TotalGHGEmissions']\n",
    "dataframe = data\n",
    "\n",
    "# concatenating rows with missing values on any target\n",
    "for target in target_cols:\n",
    "    production_set = pd.concat([\n",
    "        production_set,\n",
    "        missing_target(dataframe, target)\n",
    "    ])\n",
    "\n",
    "# dropping duplicates rows (missing several targets)\n",
    "production_set = production_set.drop_duplicates(keep='first')\n",
    "\n",
    "# Display the 'production set' on which to apply the ML model\n",
    "production_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons que nous n'avons ici qu'un seul bâtiment pour lequel les deux valeurs cibles ne sont pas renseignées. Nous utiliserons ce jeu de donner pour valider le flux de travail à l'issue de la modélisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation des variables explicatives et des étiquettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features : all data DataFrame, except targets (2 last columns)\n",
    "X = data.iloc[:, 0:-2]\n",
    "\n",
    "# Targets : projection on multiple columns, by name\n",
    "y = data[['SiteEnergyUse(kBtu)','TotalGHGEmissions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BuildingType</th>\n",
       "      <th>PrimaryPropertyType</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>PropertyGFAParking</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>LargestPropertyUseType</th>\n",
       "      <th>LargestPropertyUseTypeGFA</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multifamily LR (1-4)</td>\n",
       "      <td>Low-Rise Multifamily</td>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>48383.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48383.0</td>\n",
       "      <td>Multifamily Housing</td>\n",
       "      <td>38172.000000</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multifamily LR (1-4)</td>\n",
       "      <td>Low-Rise Multifamily</td>\n",
       "      <td>DELRIDGE</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52134.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52134.0</td>\n",
       "      <td>Multifamily Housing</td>\n",
       "      <td>52134.000000</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NonResidential</td>\n",
       "      <td>Retail Store</td>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111077.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111077.0</td>\n",
       "      <td>Retail Store</td>\n",
       "      <td>101528.658703</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NonResidential</td>\n",
       "      <td>Small- and Mid-Sized Office</td>\n",
       "      <td>DOWNTOWN</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>98370.0</td>\n",
       "      <td>25920.0</td>\n",
       "      <td>72450.0</td>\n",
       "      <td>Office</td>\n",
       "      <td>98370.000000</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NonResidential</td>\n",
       "      <td>Large Office</td>\n",
       "      <td>LAKE UNION</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>193788.0</td>\n",
       "      <td>37854.0</td>\n",
       "      <td>155934.0</td>\n",
       "      <td>Office</td>\n",
       "      <td>138672.000000</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BuildingType          PrimaryPropertyType Neighborhood  YearBuilt  \\\n",
       "0  Multifamily LR (1-4)         Low-Rise Multifamily     DOWNTOWN     1900.0   \n",
       "1  Multifamily LR (1-4)         Low-Rise Multifamily     DELRIDGE     2007.0   \n",
       "2        NonResidential                 Retail Store     DOWNTOWN     1989.0   \n",
       "3        NonResidential  Small- and Mid-Sized Office     DOWNTOWN     1906.0   \n",
       "4        NonResidential                 Large Office   LAKE UNION     1947.0   \n",
       "\n",
       "   NumberofBuildings  NumberofFloors  PropertyGFATotal  PropertyGFAParking  \\\n",
       "0                1.0             4.0           48383.0                 0.0   \n",
       "1                1.0             4.0           52134.0                 0.0   \n",
       "2                1.0             4.0          111077.0                 0.0   \n",
       "3                1.0             6.0           98370.0             25920.0   \n",
       "4                1.0             4.0          193788.0             37854.0   \n",
       "\n",
       "   PropertyGFABuilding(s) LargestPropertyUseType  LargestPropertyUseTypeGFA  \\\n",
       "0                 48383.0    Multifamily Housing               38172.000000   \n",
       "1                 52134.0    Multifamily Housing               52134.000000   \n",
       "2                111077.0           Retail Store              101528.658703   \n",
       "3                 72450.0                 Office               98370.000000   \n",
       "4                155934.0                 Office              138672.000000   \n",
       "\n",
       "   ENERGYSTARScore  \n",
       "0             75.0  \n",
       "1             85.0  \n",
       "2             91.0  \n",
       "3             45.0  \n",
       "4             59.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteEnergyUse(kBtu)</th>\n",
       "      <th>TotalGHGEmissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2953338.0</td>\n",
       "      <td>112.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1212551.0</td>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9898724.0</td>\n",
       "      <td>69.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6525887.0</td>\n",
       "      <td>47.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16760217.0</td>\n",
       "      <td>116.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SiteEnergyUse(kBtu)  TotalGHGEmissions\n",
       "0            2953338.0             112.06\n",
       "1            1212551.0               8.45\n",
       "2            9898724.0              69.01\n",
       "3            6525887.0              47.24\n",
       "4           16760217.0             116.84"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation du jeu de données d'entraînement et du jeu de données de test\n",
    "Remarque : comme les hyperparamètres et le modèle seront séléctionnées par validation croisée, le jeu de données d'entraînement servira à la fois pour l'entraînement et la validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition de la \"graine\" pour le générateur pseudo-aléatoire\n",
    "Sélectionner cette graine nous permet d'opérer, lors des validations croisées imbriquées, sur les mêmes plis (\"folds\") pour chaque modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random integer (seed)\n",
    "seed = 42\n",
    "\n",
    "# Seed the generator of pseudo-random number.\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un modèle naïf (\"baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix des hyperparamètres et sélection du modèle\n",
    "Nous procédons à une validation croisée pour sélectionner les hyperparamètres et le modèle.\n",
    "\n",
    "Pour que le prétraitement soit réalisé sans fuite de données, nous utiliserons un « pipeline »."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition du prétraitement différencié selon les colonnes\n",
    "\n",
    "Pour éviter les \"fuites de données\", nous effectuerons les transformations de prétraitement dans un \"pipe-line\" intégré à la recherche sur grille avec validation croisée :\n",
    "* imputation\n",
    "* standardisation\n",
    "* passage au log\n",
    "* *target encoding*\n",
    "* interaction and polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features:\n",
      " ['YearBuilt', 'NumberofBuildings', 'NumberofFloors', 'PropertyGFATotal', 'PropertyGFAParking', 'PropertyGFABuilding(s)', 'LargestPropertyUseTypeGFA', 'ENERGYSTARScore']\n",
      "\n",
      "Categorical features:\n",
      " ['BuildingType', 'PrimaryPropertyType', 'Neighborhood', 'LargestPropertyUseType']\n"
     ]
    }
   ],
   "source": [
    "# Select numerical columns\n",
    "numeric_features = list(X.select_dtypes(include='number').columns)\n",
    "print(\"Numeric features:\\n\", numeric_features)\n",
    "\n",
    "# Select categorical columns (ordered and non-ordered)\n",
    "categorical_features = list(X.select_dtypes(include='category').columns)\n",
    "print(\"\\nCategorical features:\\n\", categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Preprocessing pipeline for numeric features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=10, random_state=0)), # iterative imputation\n",
    "    ('scaler', StandardScaler()), # standardization\n",
    "     ])\n",
    "\n",
    "# Preprocessing pipeline for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')), # simple imputation\n",
    "    ('target_encoder', TargetEncoder()) # target encoding\n",
    "    ])\n",
    "\n",
    "# Preprocessing column-wise using pipelines for numeric and categorical features\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing preprocessing pipeline\n",
    "X_preprocessed = preprocessor.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.19472912e+00, -4.41353200e-02, -3.09537688e-01, -8.24898934e-02,\n",
       "        3.56414564e-01, -1.44776908e-01, -1.18447792e-01,  3.40097633e-01,\n",
       "        7.81636253e+06,  5.03300237e+06,  4.88402604e+06,  9.15739357e+06])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_preprocessed[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! Attention : le target encoding doit être effectué avant la séparation des variables explicatives et des étiquettes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = ['age', 'fare']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['embarked', 'sex', 'pclass']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(solver='lbfgs'))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition du pipe-line\n",
    "Nous définissons un pipe-line incluant tout le pré-traitement et un modèle de regression fantôche.\n",
    "\n",
    "Les véritables modèles seront définis dans les grilles de recherche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"preprocess\", preprocessor), # preprocessing steps\n",
    "    (\"regressor\", LinearRegression()), # dummy regression model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   IterativeImputer(add_indicator=False,\n",
       "                                                                                    estimator=None,\n",
       "                                                                                    imputation_order='ascending',\n",
       "                                                                                    initial_strategy='mean',\n",
       "                                                                                    max_iter=10,\n",
       "                                                                                    max_value=None,\n",
       "                                                                                    min_value=None,\n",
       "                                                                                    missing_...\n",
       "                                                                   TargetEncoder(cols=None,\n",
       "                                                                                 drop_invariant=False,\n",
       "                                                                                 handle_unknown='impute',\n",
       "                                                                                 impute_missing=True,\n",
       "                                                                                 min_samples_leaf=1,\n",
       "                                                                                 return_df=True,\n",
       "                                                                                 smoothing=1.0,\n",
       "                                                                                 verbose=0))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['BuildingType',\n",
       "                                                   'PrimaryPropertyType',\n",
       "                                                   'Neighborhood',\n",
       "                                                   'LargestPropertyUseType'])],\n",
       "                                   verbose=False)),\n",
       "                ('regressor',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing generic pipeline\n",
    "pipe.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des espaces de recherche\n",
    "Pour des raisons de performances, nous choississons d'établir une grille de recherche distincte pour chacun des modèles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Create space of candidate values for models and hyperparameters\n",
    "search_space = [{\n",
    "    \"regressor\": [ElasticNet(max_iter=10000)], # elastic net regressor\n",
    "    \"regressor__alpha\": np.logspace(0, 4, 10), # constant that multiplies the penalty terms\n",
    "    \"regressor__l1_ratio\": [0, 0.5, 1] #  mixing parameter\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(0, 4, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition de la grille de recherche avec validation croisée (interne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : nous conservons la métrique par défaut de scikit-learn pour les régression : le score R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create grid search\n",
    "gridsearch = GridSearchCV(\n",
    "    pipe, # use of the pipeline (preprocessing + model)\n",
    "    search_space, # choice of hyper-parameters to test\n",
    "    cv=5, # numbers of folds\n",
    "    n_jobs=-1, # use all available cores (parallelization)\n",
    "    iid=False, # to avoid a DeprecationWarning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "           max_iter=10000, normalize=False, positive=False, precompute=False,\n",
       "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the GridSearchCV\n",
    "best_model = gridsearch.fit(X, y)\n",
    "\n",
    "# Getting the parameters of the best model\n",
    "best_model.best_estimator_.get_params()['regressor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthodes spécifiques de sélection des hyper-paramètres\n",
    "Scikit-learn propose des méthodes de sélection des hyper-paramètres spécifiques à certains algorithmes d'apprentissage automatique.\n",
    "\n",
    "See also : https://scikit-learn.org/stable/modules/grid_search.html#model-specific-cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation finale du modèle sélectionné par validation croisée (externe)\n",
    "Nous évaluons le modèle sélectionné, avec les hyperparamètres sélectionnés sur le jeu de données d'entraînement.\n",
    "\n",
    "Pour avoir une évaluation non-biaisée, nous utilisons une validation croisée imbriquée (\"*nested cross validation*\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-077dcd50f4c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m cross_val_score(gridsearch, X, y, \n\u001b[0;32m      6\u001b[0m                 \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# default, but specified to silence warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# default, but specified to silence warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m                ).mean()\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 231\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    685\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    664\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 666\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    853\u001b[0m                     \u001b[1;31m# scheduling.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[1;34m(self, ensure_ready)\u001b[0m\n\u001b[0;32m    536\u001b[0m         \"\"\"Shutdown the workers and restart a new one with the same parameters\n\u001b[0;32m    537\u001b[0m         \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m         \u001b[0mdelete_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_temp_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\u001b[0m in \u001b[0;36mshutdown\u001b[1;34m(self, wait, kill_workers)\u001b[0m\n\u001b[0;32m   1094\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1096\u001b[1;33m                 \u001b[0mqmt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[0mcq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_queue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\threading.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m             \u001b[1;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# already determined that the C code is done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Conduct nested cross-validation and output the average score\n",
    "cross_val_score(gridsearch, X, y, \n",
    "                cv=5, # default, but specified to silence warning\n",
    "                scoring='r2', # default, but specified to silence warning\n",
    "               ).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ré-entraînement final du modèle sur l'ensemble du jeu de données \n",
    "Nous ré-entraînons le modèle sélectionné, en utilisant les hyperparamètres sélectionnés par validation croisé sur l'ensemble du jeu de données pour lequel nous disposons des étiquettes cibles : le jeu de données d'entraînement et le jeu de données de test.\n",
    "\n",
    "Remarque : peut-être fait automatiquement par la validation croisée ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact des valeurs hors-normes (\"*outliers*\")\n",
    "Précédemment nous avons identifiés les valeurs hors-normes. Nous allons tester si le modèle est plus performant lorsque l'on conserve ou que l'on élimine ces valeurs hors-normes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Détection et traitement des valeurs \"hors normes\"\n",
    "Nous utilisons la méthode de l'ellipse, basée sur l'hypothèse que les données sont normalement distribuées.\n",
    "\n",
    "Après la standardisation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elliptic_outliers(dataframe, contamination=0.1):\n",
    "    \"\"\"This function returns outliers based on the EllpticEnvelope methode.\n",
    "    It assumes that the (numerical) features are normally distributed\n",
    "    and take the rate of outliers (contamination) as parameter.\"\"\"\n",
    "\n",
    "    # Load libraries\n",
    "    from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "    # Create detector\n",
    "    outlier_detector = EllipticEnvelope(contamination=contamination)\n",
    "\n",
    "    # Fit detector\n",
    "    outlier_detector.fit(dataframe)\n",
    "\n",
    "    # Predict outliers\n",
    "    outlier_detector.predict(dataframe)\n",
    "\n",
    "    # Define mask of predicted outliers\n",
    "    mask = outlier_detector.predict(dataframe) == -1\n",
    "\n",
    "    # Apply the mask to the data\n",
    "    return dataframe[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Multifamily LR (1-4)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-ef14e03ac348>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcontamination\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0melliptic_outliers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontamination\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-42-149be83dc73e>\u001b[0m in \u001b[0;36melliptic_outliers\u001b[1;34m(dataframe, contamination)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Fit detector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0moutlier_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Predict outliers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\sklearn\\covariance\\elliptic_envelope.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \"\"\"\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffset_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontamination\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\sklearn\\covariance\\robust_covariance.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \"\"\"\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'MinCovDet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DS_projet3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Multifamily LR (1-4)'"
     ]
    }
   ],
   "source": [
    "dataframe = data\n",
    "contamination = 0.1\n",
    "\n",
    "elliptic_outliers(dataframe, contamination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation du meilleur modèle ré-entraîné pour la prédiction\n",
    "Nous ne disposons que d'une seule ligne données sur laquelle utiliser notre modèle pour estimer la consommation d'énergie et l'émission de gaz à effets de serre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Élimination des colonnes d'étiquettes\n",
    "Afin d'avoir un jeu de données ayant le même format que le jeu d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "production_set = production_set.drop(target_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation des données à évaluer avec les étapes de prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming data with preprocessing steps…\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des effets de la taille du jeu de données d'entraînement\n",
    "Nous étudions l'impact de la taille du jeu de données d'entraînement pour déterminer si notre modèle gagnerait en exactitude à être entraîné sur un nombre plus important de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Évaluer l’intérêt de l’\"ENERGY STAR Score\"\n",
    "Nous cherchons à évaluer l'intérêt de l’\"ENERGY STAR Score\" pour la prédiction d’émissions, qui est fastidieux à calculer avec l’approche utilisée actuellement par l'équipe.\n",
    "* 'ENERGYSTARScore' : An EPA calculated 1-100 rating that assesses a property’s overall energy performance, based on national data to control for differences among climate, building uses, and operations. A score of 50 represents the national median.\n",
    "* Voir aussi : https://www.energystar.gov/buildings/facility-owners-and-managers/existing-buildings/use-portfolio-manager/interpret-your-results/what"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "\n",
    "\n",
    "# Performance of the model without the 'ENERGYSTARScore'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde du modèle\n",
    "Nous sauvegardons le modèle dans un fichier pickle pour usage ultérieur.\n",
    "\n",
    "Nous indiquons dans le nom du fichier la version de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Get scikit-learn version\n",
    "scikit_version = joblib.__version__\n",
    "\n",
    "# Save model as pickle file\n",
    "joblib.dump(model, \"model_{version}.pkl\".format(version=scikit_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from file\n",
    "regressor = joblib.load(\"model_0.22.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO LIST\n",
    "* afficher les marges d'erreur des régressions\n",
    "* afficher la variance des performances des modèles\n",
    "* courbes pour les performances des modèles en fonction des hyper-paramètres\n",
    "* intégrer les imputeurs à la pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
